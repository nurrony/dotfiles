#!/usr/bin/env bash
# Bash wrappers for containers run commands
export CONTAINER_REPO_PREFIX=jess


# run the following commands sshing into the podman machine
# sudo ln -s /Users/nurrony/.config/containers/registries.conf \
#  /etc/containers/registries.conf.d/999-podman-desktop-registries-from-host.conf
alias mypodmachine="podman machine init rons-podman-machine --now --cpus 4 --disk-size 100 --memory 8192 --volume /Users:/Users --volume /private:/private --volume /var/folders:/var/folders --volume $DEV_ZONE:$DEV_ZONE --rootful"

dlog() {
  docker logs -f --tail 100 "$@"
}

# cleans all docker resources. run it cautiously
podcleanup() {
  docker container prune --force 2>/dev/null
  docker volume prune --force 2>/dev/null
  docker image prune --force --build-cache --all 2>/dev/null
}

# deletes stopped containers
del_stopped() {
  local name=$1
  local state
  state=$(docker inspect --format "{{.State.Running}}" "$name" 2>/dev/null)

  if [[ "$state" == "false" ]]; then
    docker rm "$name"
  fi
}

# bring up local container registry
ctr-registry-up() {
  local state=$(docker inspect --format "{{.State.Running}}" registry 2>/dev/null)
  if [[ "$state" == "true" ]] || [[ "$state" != "" ]]; then
    docker rm -f registry
  fi
  docker compose -f $DEV_ZONE_CONFIG_PATH/kubernetes/clusters/docker-compose.yml up -d
  echo 'registry started successfully...'
}

# down local container registry
ctr-rgistry-down() {
  docker compose -f $DEV_ZONE_CONFIG_PATH/kubernetes/clusters/docker-compose.yml down
  echo 'registry is down successfully'
}

# checks if target container relies on other and ensure to run dependent
# containers before running the target container
relies_on() {
  for container in "$@"; do
    local state
    state=$(docker inspect --format "{{.State.Running}}" "$container" 2>/dev/null)

    if [[ "$state" == "false" ]] || [[ "$state" == "" ]]; then
      echo "$container is not running, starting it for you."
      $container
    fi
  done
}

nginx-proxy() {
  del_stopped nginx-proxy
  local state=$(docker inspect --format "{{.State.Running}}" nginx-proxy 2>/dev/null)

  if [[ "$state" == "false" ]] || [[ "$state" == "" ]]; then
    mkdir -p $DEV_ZONE_CONFIG_PATH/nginx/{certs,vhost.d,conf.d};
    docker container run -it -d \
      --privileged \
      --network ${DEV_CONTAINER_NETWORK_NAME} \
      --publish 80:80 \
      --publish 443:443 \
      --name nginx-proxy \
      --volume /var/run/docker.sock:/tmp/docker.sock:ro \
      --volume $DEV_ZONE_CONFIG_PATH/nginx/certs:/etc/nginx/certs:ro \
      --volume $DEV_ZONE_CONFIG_PATH/nginx/vhost.d:/etc/nginx/vhost.d:ro \
      --volume $DEV_ZONE_CONFIG_PATH/nginx/conf.d/custom_settings.conf:/etc/nginx/conf.d/custom_settings.conf:ro \
      nginxproxy/nginx-proxy:alpine
  else
    echo 'proxy is already running'
  fi
}

proxy-manager() {
  del_stopped proxy-manager
  local state=$(docker inspect --format "{{.State.Running}}" proxy-manager 2>/dev/null)

  if [[ "$state" == "false" ]] || [[ "$state" == "" ]]; then
    mkdir -p $DEV_ZONE_CONFIG_PATH/nginx/manager/{data,letsencrypt};
    docker run -it --detach \
      --privileged \
      --name proxy-manager \
      --publish 80:80 \
      --publish 443:443 \
      --publish 8888:81 \
      --network ${DEV_CONTAINER_NETWORK_NAME} \
      --volume $DEV_ZONE_CONFIG_PATH/nginx/manager/data:/data:Z \
      --volume $DEV_ZONE_CONFIG_PATH/nginx/manager/letsencrypt:/etc/letsencrypt:Z \
      --env DB_SQLITE_FILE="/data/database.sqlite" \
      jc21/nginx-proxy-manager:latest
  else
    echo 'proxy is already running'
  fi
}

portainer() {
  relies_on nginx-proxy
  del_stopped portainer
  local state=$(docker inspect --format "{{.State.Running}}" portainer 2>/dev/null)

  if [[ "$state" == "false" ]] || [[ "$state" == "" ]]; then
    echo "portainer server is not running, starting it for you."
    mkdir -p $DEV_ZONE_CONFIG_PATH/portainer;
    docker container run -it -d --privileged \
      --volume /var/run/docker.sock:/var/run/docker.sock:ro \
      --volume $DEV_ZONE_CONFIG_PATH/portainer:/data \
      --env VIRTUAL_HOST=portainer.nurrony.localhost \
      --expose 9000 \
      --network ${DEV_CONTAINER_NETWORK_NAME} \
      --name portainer \
      portainer/portainer
  else
    echo 'portainer is already running'
  fi
}

# creates an nginx config for a local route
nginx_config() {
  server=$1
  route=$2

  cat >$DEV_ZONE_CONFIG_PATH/nginx/conf.d/${server}.conf <<-EOF
upstream ${server} { server ${route}; }
  server {
    server_name ${server};
    location / {
    proxy_pass  http://${server};
    proxy_http_version 1.1;
    proxy_set_header Upgrade \$http_upgrade;
    proxy_set_header Connection "upgrade";
    proxy_set_header Host \$http_host;
    proxy_set_header X-Forwarded-Proto \$scheme;
    proxy_set_header X-Forwarded-For \$remote_addr;
    proxy_set_header X-Forwarded-Port \$server_port;
    proxy_set_header X-Request-Start \$msec;
  }
}
EOF

  # restart nginx
  docker restart nginx

  # add host to /etc/hosts
  hostess add $server 127.0.0.1

  # open browser
  open "http://${server}"
}

dhtop() {
  docker container run --rm -it \
    --pid host \
    --network none \
    --name htop \
    ${CONTAINER_REPO_PREFIX}/htop
}

mysqlserver() {
  local VERSION=${1:-8.0}
  local PORT=${2:-3306}
  del_stopped mysqlserver-${VERSION//./-}
  local state=$(docker inspect --format "{{.State.Running}}" mysqlserver-${VERSION//./-} 2>/dev/null)

  if [[ "$state" == "false" ]] || [[ "$state" == "" ]]; then
    echo "mysql $VERSION server is not running, starting it for you."
    mkdir -p $DEV_ZONE_CONFIG_PATH/databases/mysql/${VERSION} &&
      docker run -it -d \
        --volume $DEV_ZONE_CONFIG_PATH/databases/mysql/${VERSION}:/var/lib/mysql \
        --env MYSQL_ROOT_PASSWORD=nurrony \
        --publish $PORT:3306 \
        --network ${DEV_CONTAINER_NETWORK_NAME} \
        --name mysqlserver-${VERSION//./-} \
        mysql:${VERSION}
  else
    echo "mysql server $VERSION is already running"
  fi
}

nifiserver() {
  local VERSION=${1:-latest}
  local PORT=${2:-8443}
  del_stopped nifiserver-${VERSION//./-}
  local state=$(docker inspect --format "{{.State.Running}}" nifiserver-${VERSION//./-} 2>/dev/null)

  if [[ "$state" == "false" ]] || [[ "$state" == "" ]]; then
    echo "nifiserver $VERSION server is not running, starting it for you."
    mkdir -p $DEV_ZONE_CONFIG_PATH/nifiserver/${VERSION//./-} &&
      docker run -it -d \
        --publish $PORT:8443 \
        --name nifiserver-${VERSION//./-} \
        --hostname nifiserver-${VERSION//./-} \
        --network ${DEV_CONTAINER_NETWORK_NAME} \
        --env SINGLE_USER_CREDENTIALS_USERNAME=admin \
        --env SINGLE_USER_CREDENTIALS_PASSWORD=NifiAdmin@121 \
        --env NIFI_WEB_HTTPS_HOST=nifiserver-${VERSION//./-} \
        --mount type=bind,source="$(realpath "${DEV_ZONE_CONFIG_PATH}/nifiserver/${VERSION//./-}")",target=/opt/nifi/nifi-current \
        apache/nifi:${VERSION}
  else
    echo "nifi server $VERSION is already running"
  fi
}

mysql() {
  local RUNNING_DBSERVER_NAME=$(docker ps --filter "name=mysqlserver" --format "{{.Names}}")
  relies_on $RUNNING_DBSERVER_NAME
  docker exec -it $RUNNING_DBSERVER_NAME mysql "$@"
}

dynamodb() {
  del_stopped dynamodb
  relies_on nginx-proxy
  sleep 2
  local state=$(docker inspect --format "{{.State.Running}}" dynamodb 2>/dev/null)

  if [[ "$state" == "false" ]] || [[ "$state" == "" ]]; then
    echo "local dynamodb server is not running, starting it for you."
    mkdir -p $DEV_ZONE_CONFIG_PATH/databases/dynamodb;
    docker container run -dit \
      --volume $DEV_ZONE_CONFIG_PATH/databases/dynamodb:/home/dynamodblocal/data \
      --workdir /home/dynamodblocal \
      --publish "8000:8000" \
      --expose 8000 \
      --env VIRTUAL_HOST=dynamodb.nurrony.localhost \
      --network ${DEV_CONTAINER_NETWORK_NAME} \
      --name dynamodb \
      amazon/dynamodb-local -jar DynamoDBLocal.jar -sharedDb -optimizeDbBeforeStartup -dbPath ./data
    if [ "$1" != "" ]; then
      docker network connect $1 dynamodb
    fi
  else
    echo 'local dynamodb server is already running'
  fi

}

pma() {
  del_stopped pma
  relies_on nginx-proxy
  sleep 2
  local state=$(docker inspect --format "{{.State.Running}}" pma 2>/dev/null)

  if [[ "$state" == "false" ]] || [[ "$state" == "" ]]; then
    echo "phpMyAdmin is not running, starting it for you."
    docker container run -it -d \
      --env UPLOAD_LIMIT=100M \
      --env VIRTUAL_HOST=pma.nurrony.localhost \
      --env PMA_ARBITRARY=1 \
      --network ${DEV_CONTAINER_NETWORK_NAME} \
      --expose 80 \
      --name pma \
      phpmyadmin/phpmyadmin
  else
    echo 'phpMyAdmin is already running'
  fi
}

myblog() {
  relies_on nginx-proxy
  relies_on mysqlserver
  sleep 5
  del_stopped personal-blog
  local state=$(docker inspect --format "{{.State.Running}}" personal-blog 2>/dev/null)

  if [[ "$state" == "false" ]] || [[ "$state" == "" ]]; then
    echo "blog server is not running, starting it for you."
    docker container run -it -d \
      --volume ${DEV_ZONE}/projects/open-sources/nurrony.info/ghost-content:/var/lib/ghost/content \
      --env VIRTUAL_HOST=blog.nurrony.localhost \
      --env url=http://blog.nurrony.localhost \
      --env database__client=mysql \
      --env database__connection__host=mysqlserver \
      --env database__connection__user=root \
      --env database__connection__password=nurrony \
      --env database__connection__database=rons_blog \
      --env DEV_DOMAIN=http://blog.nurrony.localhost \
      --network ${DEV_CONTAINER_NETWORK_NAME} \
      --name personal-blog \
      ghost:2-alpine
  else
    echo 'blog is already running'
  fi
}

mongoserver() {
  local VERSION=${1:-7}
  local PORT=${2:-27017}
  local DBNAME=${3:-experiments}
  local state=$(docker inspect --format "{{.State.Running}}" mongoserver$VERSION 2>/dev/null)
  del_stopped mongoserver${VERSION}
  if [[ "$state" == "false" ]] || [[ "$state" == "" ]]; then
    echo "mongoserver ${VERSION}.x.x is not running, starting it for you."
    mkdir -p $DEV_ZONE_CONFIG_PATH/databases/mongodb/$VERSION;
    docker container run -dit \
      --user $(id -u):$(id -g) \
      --volume $DEV_ZONE_CONFIG_PATH/databases/mongodb/$VERSION:/data/db \
      --env MONGODB_INITDB_ROOT_USERNAME=root \
      --env MONGODB_INITDB_ROOT_PASSWORD=nurrony \
      --publish $PORT:27017 \
      --network ${DEV_CONTAINER_NETWORK_NAME} \
      --name mongoserver$VERSION \
      mongo:${VERSION}
  else
    echo "mongoserver $VERSION.x.x is already running"
  fi
}

mongo() {
  docker exec -t mongoserver5 mongo "$@"
}

# check https://github.com/GoogleCloudPlatform/click-to-deploy/blob/master/docker/rabbitmq/README.md
rabbitmq() {
  del_stopped rabbitmq
  local state=$(docker inspect --format "{{.State.Running}}" rabbitmq 2>/dev/null)
  if [[ "$state" == "false" ]] || [[ "$state" == "" ]]; then
    echo "rabbitmq broker is not running, starting it for you."
    mkdir -p $DEV_ZONE_CONFIG_PATH/rabbitmq/{certs,data};
    docker container run --detach -it \
      --name rabbitmq \
      --hostname rabbitmq \
      --publish 5672:5672 \
      --publish 15672:15672 \
      --network ${DEV_CONTAINER_NETWORK_NAME} \
      --env RABBITMQ_DEFAULT_USER=admin \
      --env RABBITMQ_DEFAULT_PASS=nurrony \
      --volume $DEV_ZONE_CONFIG_PATH/rabbitmq/certs:/etc/rabbitmq/ssl \
      --volume $DEV_ZONE_CONFIG_PATH/rabbitmq/data:/var/lib/rabbitmq \
      --volume $DEV_ZONE_CONFIG_PATH/rabbitmq/rabbitmq.conf:/etc/rabbitmq/conf.d/10-defaults.conf:ro \
      rabbitmq:4-management-alpine
  else
    echo "rabbitmq broker is already running"
  fi
}

# TODO: finish this
kafka() {
  local CONFLUENT_PLATFORM_VERSION=${1:-latest}
  del_stopped kafka
  local state=$(docker inspect --format "{{.State.Running}}" kafka 2>/dev/null)
  if [[ "$state" == "false" ]] || [[ "$state" == "" ]]; then
    echo "kafka broker ${VERSION} is not running, starting it for you."
    mkdir -p $DEV_ZONE_CONFIG_PATH/kafka;
    docker container run --detach -it \
      --name kafka \
      --network ${DEV_CONTAINER_NETWORK_NAME} \
      --publish 9092:9092 \
      --publish 9102:9102 \
      --env KAFKA_NODE_ID=1 \
      --env KAFKA_JMX_PORT=9102 \
      --env KAFKA_JMX_HOSTNAME=localhost \
      --env CLUSTER_ID=MkU3OEVBNTcwNTJENDM3Qk \
      --env KAFKA_TRANSACTION_STATE_LOG_MIN_ISR=1 \
      --env KAFKA_PROCESS_ROLES=broker,controller \
      --env KAFKA_LOG_DIRS=/tmp/kraft-combined-logs \
      --env KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS=0 \
      --env KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1 \
      --env KAFKA_INTER_BROKER_LISTENER_NAME=PLAINTEXT \
      --env KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER \
      --env KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka:29094 \
      --env KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1 \
      --env KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092 \
      --env KAFKA_LISTENERS=PLAINTEXT://kafka:29092,CONTROLLER://kafka:29094,PLAINTEXT_HOST://0.0.0.0:9092 \
      --env KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT \
      confluentinc/cp-kafka:${CONFLUENT_PLATFORM_VERSION:-latest}
  else
    echo "kafka broker $CONFLUENT_PLATFORM_VERSION is already running"
  fi
}

mailserver() {
  del_stopped mailserver
  relies_on nginx-proxy
  sleep 2
  local state=$(docker inspect --format "{{.State.Running}}" mailserver 2>/dev/null)
  if [[ "$state" == "false" ]] || [[ "$state" == "" ]]; then
    echo "mailserver is not running. starting is for you"
    mkdir -p $DEV_ZONE_CONFIG_PATH/mailserver;
    docker container run -d \
      --network ${DEV_CONTAINER_NETWORK_NAME} \
      --expose 8025 \
      --name mailserver \
      --publish 1025:1025 \
      --publish 1110:1110 \
      --env TZ=Asia/Dhaka \
      --env VIRTUAL_PORT=8025 \
      --env MP_SMTP_AUTH_ACCEPT_ANY=true \
      --env MP_DATABASE=/data/mailpit.db \
      --env MP_SMTP_AUTH_ALLOW_INSECURE=true \
      --env VIRTUAL_HOST=mail.nurrony.localhost \
      --volume $DEV_ZONE_CONFIG_PATH/mailserver:/data \
      axllent/mailpit:latest
  else
    echo "mailserver is already running"
  fi
}

zipkin() {
  del_stopped zipkin
  relies_on nginx-proxy
  sleep 2
  local VERSION=${1:-3}
  local state=$(docker inspect --format "{{.State.Running}}" zipkin 2>/dev/null)
  if [[ "$state" == "false" ]] || [[ "$state" == "" ]]; then
    echo "zipkin 3.x.x server is not running, starting it for you."
    docker container run --detach -it \
      --name zipkin${VERSION} \
      --network ${DEV_CONTAINER_NETWORK_NAME} \
      --publish 9411:9411 \
      --env VIRTUAL_PORT=9411 \
      --env VIRTUAL_HOST=zipkin.nurrony.localhost \
      openzipkin/zipkin:latest
  else
    echo "zipkin 3.x.x is already running"
  fi
}

# spawn up postgres server. takes version as params. defaults to 16.x.x
pgserver() {
  local VERSION=${1:-17}
  local PORT=${2:-5432}
  local DBNAME=${3:-experiments}
  del_stopped pgserver${VERSION//./-}
  local state=$(docker inspect --format "{{.State.Running}}" pgserver${VERSION//./-} 2>/dev/null)

  if [[ "$state" == "false" ]] || [[ "$state" == "" ]]; then
    mkdir -p $DEV_ZONE_CONFIG_PATH/databases/postgres/${VERSION}
    echo "postgres $VERSION.x.x server is not running, starting it for you."
    docker container run -it -d \
      --network ${DEV_CONTAINER_NETWORK_NAME} \
      --ulimit memlock=-1:-1 \
      --memory-swappiness=0 \
      --volume $DEV_ZONE_CONFIG_PATH/databases/postgres/${VERSION}:/var/lib/postgresql/data \
      --env POSTGRES_USER=postgres \
      --env POSTGRES_DB=$DBNAME \
      --env POSTGRES_PASSWORD=nurrony \
      --publish $PORT:5432 \
      --name pgserver${VERSION//./-} \
      postgres:$VERSION
  else
    echo "postgres $VERSION.x.x is already running"
  fi
}

psql() {
  local RUNNING_PGSERVER_NAME=$(docker ps --filter "name=pgserver" --format "{{.Names}}")
  relies_on $RUNNING_DBSERVER_NAME
  docker exec -it $RUNNING_PGSERVER_NAME psql "$@"
}

pga() {
  del_stopped pga
  relies_on nginx-proxy
  sleep 2
  local state=$(docker inspect --format "{{.State.Running}}" pga 2>/dev/null)

  if [[ "$state" == "false" ]] || [[ "$state" == "" ]]; then
    echo "pgAdmin4 is not running, starting it for you."
    docker container run -dit \
      --env VIRTUAL_HOST=pga.nurrony.localhost \
      --env PGADMIN_DEFAULT_EMAIL=rony@nurrony.info \
      --env PGADMIN_DEFAULT_PASSWORD=nurrony \
      --env PGADMIN_DISABLE_POSTFIX=yes \
      --network ${DEV_CONTAINER_NETWORK_NAME} \
      --expose 80 \
      --name pga \
      dpage/pgadmin4
  else
    echo 'pgAdmin4 is already running'
  fi
}

elasticsearch() {
  # Add these extra environment variables if needed
  # --env "bootstrap.memory_lock=true"
  # --env "ES_JAVA_OPTS=-Xms512m -Xmx512m"
  del_stopped elasticsearch
  local state=$(docker inspect --format "{{.State.Running}}" elasticsearch 2>/dev/null)

  if [[ "$state" == "false" ]] || [[ "$state" == "" ]]; then
    echo "elasticsearch server is not running, starting it for you."
    mkdir -p $DEV_ZONE_CONFIG_PATH/databases/elasticsearch/data;
    docker container run -it -d \
      --volume "$DEV_ZONE_CONFIG_PATH/databases/elasticsearch/data:/usr/share/elasticsearch/data" \
      --publish 9200:9200 \
      --publish 9300:9300 \
      --network ${DEV_CONTAINER_NETWORK_NAME} \
      --name elasticsearch \
      --ulimit memlock=-1:-1 \
      --env VIRTUAL_PORT=9200 \
      --env "http.cors.enabled=true" \
      --env "ELASTIC_PASSWORD=nurrony" \
      --env "discovery.type=single-node" \
      --env "xpack.security.enabled=true" \
      --env "http.cors.allow-origin=/.*/" \
      --env "http.max_content_length=200mb" \
      --env "node.name=local-elasticsearch" \
      --env "cluster.name=local-elasticsearch" \
      --env VIRTUAL_HOST=elasticserver.nurrony.localhost \
      --env "http.cors.allow-headers: X-Requested-With,Content-Type,Content-Length,Authorization" \
      docker.elastic.co/elasticsearch/elasticsearch:7.17.24 "$@"
  else
    echo 'elasticsearch server is already running'
  fi
}

elasticview() {
  del_stopped elasticvue
  relies_on elasticsearch
  relies_on nginx-proxy
  sleep 2
  local state=$(docker inspect --format "{{.State.Running}}" elasticview 2>/dev/null)

  if [[ "$state" == "false" ]] || [[ "$state" == "" ]]; then
    docker container run -dit \
      --expose 8080 \
      --network ${DEV_CONTAINER_NETWORK_NAME} \
      --name elasticview \
      --env VIRTUAL_PORT=8080 \
      --env VIRTUAL_HOST=elasticsearch.nurrony.localhost \
      --volume "$DEV_ZONE_CONFIG_PATH/databases/elasticsearch/default_clusters.json:/usr/share/nginx/html/api/default_clusters.json:ro" \
      cars10/elasticvue
  else
    echo 'elasticsearch gui is already running'
  fi

}

containerssh() {
  docker exec -it "$@"
}

composer() {
  docker container run --rm --interactive --tty \
    --volume $PWD:/app \
    --user $(id -u):$(id -g) \
    composer:lts "$@"
}

apache-php7() {
  docker container run --rm --interactive --tty \
    --volume $PWD:/var/www/html \
    --user $(id -u):$(id -g) \
    --network ${DEV_CONTAINER_NETWORK_NAME} \
    nmrony/php:7-apache "$@"
}

start-lamp-stack() {
  nginx-proxy && pma && mysqlserver && echo 'LAMP stack started successfully.'
}

stop-lamp-stack() {
  docker rm -f nginx-proxy pma mysqlserver && echo 'LAMP stack stopped successfully.'
}

sysdig() {
  del_stopped sysdig-container
  docker container run -it \
    --privileged \
    --name sysdig-container \
    --volume /var/run/docker.sock:/var/run/docker.sock \
    --volume /dev:/host/dev \
    --volume /proc:/host/proc:ro \
    --volume /boot:/host/boot:ro \
    --volume /lib/modules:/host/lib/modules:ro \
    --volume /usr:/host/usr:ro \
    sysdig/sysdig
}

bees() {
  docker container run -it --rm \
    --env NOTARY_TOKEN \
    --volume $HOME/.bees:/root/.bees \
    --volume $HOME/.boto:/root/.boto \
    --volume $HOME/.dev:/root/.ssh:ro \
    --log-driver none \
    --name bees \
    ${CONTAINER_REPO_PREFIX}/beeswithmachineguns "$@"
}

###
### Awesome sauce by @jpetazzo
###
command_not_found_handle() {
  # Check if there is a container image with that name
  if ! docker inspect --format '{{ .Author }}' "$1" >&/dev/null; then
    echo "$0: $1: command not found"
    return
  fi

  # Check that it's really the name of the image, not a prefix
  if docker inspect --format '{{ .Id }}' "$1" | grep -q "^$1"; then
    echo "$0: $1: command not found"
    return
  fi

  #  docker container run -ti -u $(whoami) -w "$HOME" \
  #   $(env | cut -d= -f1 | awk '{print "-e", $1}') \
  #   --device /dev/snd \
  #   --volume /etc/passwd:/etc/passwd:ro \
  #   --volume /etc/group:/etc/group:ro \
  #   --volume /etc/localtime:/etc/localtime:ro \
  #   --volume /home:/home \
  #   --volume /tmp/.X11-unix:/tmp/.X11-unix \
  #   "${CONTAINER_REPO_PREFIX}/$@"
}

dive() {
  del_stopped dive
  docker container run --rm -it --privileged \
    --network ${DEV_CONTAINER_NETWORK_NAME} \
    --name dive \
    --volume /var/run/docker.sock:/var/run/docker.sock:ro \
    wagoodman/dive:latest "$@"
}

lazyvim() {
  docker container run --interactive --tty --rm \
    --workdir /root alpine:edge sh -uelic '
    apk add git lazygit neovim ripgrep alpine-sdk --update
    git clone https://github.com/LazyVim/starter ~/.config/nvim
    cd ~/.config/nvim
    nvim
  '
}

keycloak() {
  del_stopped keycloak
  relies_on nginx-proxy
  sleep 2
  local state=$(docker inspect --format "{{.State.Running}}" pga 2>/dev/null)

  if [[ "$state" == "false" ]] || [[ "$state" == "" ]]; then
    echo "starting keycloak server for you"
    docker container run -dit --expose 8080 \
      --expose 9000 \
      --expose 8443 \
      --name keycloak \
      --publish 8080:8080 \
      --publish 9000:9000 \
      --env VIRTUAL_PORT=8080 \
      --env KC_HEALTH_ENABLED=true \
      --env KC_BOOTSTRAP_ADMIN_USERNAME="root" \
      --env KC_BOOTSTRAP_ADMIN_PASSWORD="nurrony" \
      --env VIRTUAL_HOST=keycloak.nurrony.localhost \
      quay.io/keycloak/keycloak:latest start-dev
  else
    echo "keycloak server is already running"
  fi

}

grafana() {
  del_stopped grafana
  relies_on nginx-proxy
  sleep 2
  local GRAFANA_PORT=${1:-3000}
  local GRAFANA_IMG=${2:-latest}
  local state=$(docker inspect --format "{{.State.Running}}" grafana 2>/dev/null)
  if [[ "$state" == "false" ]] || [[ "$state" == "" ]]; then
    echo "grafana is not running. starting grafana server for you"
    mkdir -p $DEV_ZONE_CONFIG_PATH/monitoring/grafana/data;
    docker container run -dit --name grafana \
      --network ${DEV_CONTAINER_NETWORK_NAME} \
      --expose 3000 \
      --publish ${GRAFANA_PORT}:3000 \
      --env VIRTUAL_HOST="grafana.nurrony.localhost" \
      --env GF_FEATURE_TOGGLES_ENABLE="traceqlEditor metricsSummary" \
      --env GF_FEATURE_TOGGLES_ENABLE="accessControlOnCall" \
      --env GF_INSTALL_PLUGINS="https://storage.googleapis.com/integration-artifacts/grafana-lokiexplore-app/grafana-lokiexplore-app-latest.zip;grafana-lokiexplore-app" \
      --volume "$DEV_ZONE_CONFIG_PATH/monitoring/grafana/data:/var/lib/grafana" \
      grafana/grafana:${GRAFANA_IMG}
  fi
}

gitlab() {
  del_stopped gitlab
  local state=$(docker inspect --format "{{.State.Running}}" gitlab 2>/dev/null)
  if [[ "$state" == "false" ]] || [[ "$state" == "" ]]; then
    relies_on nginx-proxy
    echo "gitlab server is not running, starting it for you."
    mkdir -p $DEV_ZONE_CONFIG_PATH/gitlab/storage/{runner,gitlab/{configs,data,logs}};
    docker run -dit \
      --expose 80 \
      --shm-size=256m \
      --publish 8888:80 \
      --publish 22022:22 \
      --name git.nurrony.localhost \
      --hostname git.nurrony.localhost \
      --network ${DEV_CONTAINER_NETWORK_NAME} \
      --volume $DEV_ZONE_CONFIG_PATH/gitlab/gitlab.rb:/gitlab.rb \
      --volume $DEV_ZONE_CONFIG_PATH/gitlab/storage/gitlab/configs:/etc/gitlab \
      --volume $DEV_ZONE_CONFIG_PATH/gitlab/storage/gitlab/data:/var/opt/gitlab \
      --volume $DEV_ZONE_CONFIG_PATH/gitlab/storage/gitlab/logs:/var/log/gitlab \
      --env VIRTUAL_PORT=80 \
      --env GITLAB_OMNIBUS_CONFIG="from_file('/gitlab.rb')" \
      --env VIRTUAL_HOST=git.nurrony.localhost,registry-git.nurrony.localhost \
      gitlab/gitlab-ce:latest
  else
    echo "gitlab server is already running"
  fi
}

sonarqube() {
  del_stopped sonarqube
  local state=$(docker inspect --format "{{.State.Running}}" sonarqube 2>/dev/null)
  if [[ "$state" == "false" ]] || [[ "$state" == "" ]]; then
    relies_on nginx-proxy
    relies_on pgserver
    local RUNNING_PGSERVER_NAME=$(docker ps --filter "name=pgserver" --format "{{.Names}}")
    echo "sonarqube server is not running, starting it for you."
    mkdir -p $DEV_ZONE_CONFIG_PATH/sonarqube/{configs,storage/{extensions,data,logs}};
    docker run -dit \
      --publish 9000:9000 \
      --env VIRTUAL_PORT=9000 \
      --env SONAR_JDBC_PASSWORD=nurrony \
      --env SONAR_JDBC_USERNAME=postgres \
      --name sonarqube.nurrony.localhost \
      --hostname sonarqube.nurrony.localhost \
      --env VIRTUAL_HOST=sonarqube.nurrony.localhost \
      --env SONAR_JDBC_URL=jdbc:postgresql://${RUNNING_PGSERVER_NAME}:5432/sonarqube \
      --volume $DEV_ZONE_CONFIG_PATH/sonarqube/storage/data:/opt/sonarqube/data \
      --volume $DEV_ZONE_CONFIG_PATH/sonarqube/storage/logs:/opt/sonarqube/logs \
      --volume $DEV_ZONE_CONFIG_PATH/sonarqube/storage/extensions:/opt/sonarqube/extensions \
      --volume $DEV_ZONE_CONFIG_PATH/sonarqube/configs/99-sonarqube.conf:/etc/sysctl.d/99-sonarqube.conf:ro \
      --network ${DEV_CONTAINER_NETWORK_NAME} \
      sonarqube:community
  else
    echo "sonarqube server is already running"
  fi

}

jenkins() {
  del_stopped jenkins
  del_stopped jenkins-dind
  local state=$(docker inspect --format "{{.State.Running}}" jenkins 2>/dev/null)
  local dind_state=$(docker inspect --format "{{.State.Running}}" jenkins-dind 2>/dev/null)
  mkdir -p ${DEV_ZONE_CONFIG_PATH}/jenkins/{certs,data};
  if [[ "$state" == "false" ]] || [[ "$state" == "" ]]; then
    local IMAGE_NAME="nmrony/jenkins:lts-jdk21-docker"
    relies_on nginx-proxy
    # Check if the image exists locally
    if ! docker image inspect "$IMAGE_NAME" > /dev/null 2>&1; then
      echo "${IMAGE_NAME} not found locally. Building it..."
      docker build -t "$IMAGE_NAME" - <<EOF
      FROM jenkins/jenkins:lts-jdk21

      USER root
      RUN apt-get -qq --yes update && apt-get install --yes lsb-release && curl -fsSLo /usr/share/keyrings/docker-archive-keyring.asc https://download.docker.com/linux/debian/gpg
      RUN echo "deb [arch=\$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.asc] https://download.docker.com/linux/debian \$(lsb_release -cs) stable" > /etc/apt/sources.list.d/docker.list
      RUN apt-get update -qq --yes && apt-get install --yes docker-ce-cli && apt clean --yes && apt autoremove --yes && rm -rf /var/cache/apt/archives /var/lib/apt/lists/* && rm -rf /var/lib/{apt,dpkg,cache,log}/

      USER jenkins
      HEALTHCHECK --interval=30s --timeout=5s CMD curl -f http://localhost:8080/login || exit 1
EOF
    fi

  if [[ "$dind_state" == "false" ]] || [[ "$dind_state" == "" ]]; then
    echo "starting DinD container for jenkins..."
    docker run -dit --name jenkins-dind --privileged \
      --expose 2376 \
      --health-retries=5 \
      --health-timeout=5s \
      --health-interval=5s \
      --health-cmd="docker info" \
      --network-alias docker \
      --env DOCKER_TLS_CERTDIR=/certs \
      --network ${DEV_CONTAINER_NETWORK_NAME} \
      --volume "${DEV_ZONE_CONFIG_PATH}/jenkins/certs:/certs/client" \
      --volume "${DEV_ZONE_CONFIG_PATH}/jenkins/data:/var/jenkins_home" \
      docker:dind --storage-driver overlay2
      sleep 2s
    fi
    echo "jenkins server is not running. starting it for you"
    docker run -dit \
      --publish 9443:8443 \
      --publish 8080:8080 \
      --publish 50000:50000 \
      --env VIRTUAL_PORT=8080 \
      --env DOCKER_TLS_VERIFY=1 \
      --name jenkins.nurrony.localhost \
      --hostname jenkins.nurrony.localhost \
      --env DOCKER_CERT_PATH=/certs/client \
      --network ${DEV_CONTAINER_NETWORK_NAME} \
      --env DOCKER_HOST=tcp://docker:2376 \
      --env VIRTUAL_HOST=jenkins.nurrony.localhost \
      --volume "${DEV_ZONE_CONFIG_PATH}/jenkins/certs:/certs/client:ro" \
      --volume "${DEV_ZONE_CONFIG_PATH}/jenkins/data:/var/jenkins_home" \
      ${IMAGE_NAME}

  else
    echo "jenkins server is already running"
  fi
}

dind() {
  del_stopped dind
  local state=$(docker inspect --format "{{.State.Running}}" dind 2>/dev/null)
  if [[ "$state" == "false" ]] || [[ "$state" == "" ]]; then
  else
  fi
}
